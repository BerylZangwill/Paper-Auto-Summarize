"""
è®ºæ–‡èº«ä»½å¡è‡ªåŠ¨æå–è„šæœ¬ v2.0
============================================================
åŠŸèƒ½ï¼š
1. è‡ªåŠ¨åŒæ­¥ä¸»é¢˜æ¡¶é…ç½®åˆ°æ–‡ä»¶å¤¹ç»“æ„
2. æ”¯æŒæŒ‰ä¸»é¢˜æ¡¶åˆ†æ–‡ä»¶å¤¹ç®¡ç†PDF
3. äº¤äº’å¼é€‰æ‹©å¤„ç†å“ªäº›æ–‡ä»¶å¤¹
4. æ”¯æŒæ–­ç‚¹ç»­è·‘ / è¦†ç›–é‡è·‘
5. JSONæŒ‰æ–‡ä»¶å¤¹åˆ†ç»„å­˜å‚¨ï¼ŒCSVåˆ†æ–‡ä»¶å¤¹+æ€»æ±‡æ€»

æ–‡ä»¶ç»“æ„ï¼š
============================================================
project/
â”œâ”€â”€ auto_runner.py              â† ä¸»è„šæœ¬
â”œâ”€â”€ prompt_paper_extraction.md  â† Promptæ¨¡æ¿
â”œâ”€â”€ theme_buckets.md               â† ä¸»é¢˜æ¡¶é…ç½®
â”œâ”€â”€ 00_inbox_pdfs/                 â† PDFè¾“å…¥ï¼ˆæŒ‰ä¸»é¢˜åˆ†æ–‡ä»¶å¤¹ï¼‰
â”‚   â”œâ”€â”€ æ•™è‚²æ•°æ™ºåŒ–ä¸æ™ºèƒ½æ²»ç†/
â”‚   â”‚   â”œâ”€â”€ 01_è®ºæ–‡A.pdf
â”‚   â”‚   â””â”€â”€ 02_è®ºæ–‡B.pdf
â”‚   â””â”€â”€ æ•™è‚²æ²»ç†ä¸æ²»ç†ä½“ç³»ç°ä»£åŒ–/
â”‚       â””â”€â”€ 01_è®ºæ–‡C.pdf
â”œâ”€â”€ 01_extracted_json/             â† JSONè¾“å‡ºï¼ˆæŒ‰æ–‡ä»¶å¤¹åˆ†ç»„ï¼‰
â”œâ”€â”€ 02_summary_csv/                â† CSVè¾“å‡º
â”‚   â”œâ”€â”€ æ•™è‚²æ•°æ™ºåŒ–ä¸æ™ºèƒ½æ²»ç†.csv
â”‚   â””â”€â”€ _all_papers.csv            â† æ€»æ±‡æ€»
â””â”€â”€ error_log.txt                  â† é”™è¯¯æ—¥å¿—

ä½¿ç”¨æ–¹æ³•ï¼š
============================================================
1. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
   Windows CMD:    set DEEPSEEK_API_KEY=your_key
   Windows PS:     $env:DEEPSEEK_API_KEY="your_key"
   Linux/Mac:      export DEEPSEEK_API_KEY="your_key"

2. å®‰è£…ä¾èµ–ï¼š
   pip install openai pymupdf

3. è¿è¡Œè„šæœ¬ï¼š
   python auto_runner.py
"""

import os
import re
import sys
import time
import json
import csv
from pathlib import Path
from dataclasses import dataclass, field
from openai import OpenAI
import fitz  # PyMuPDF

# ============================================================
# é…ç½®åŒºåŸŸ
# ============================================================
API_KEY = os.environ.get("DEEPSEEK_API_KEY", "")
BASE_URL = "https://api.deepseek.com"
MODEL_NAME = "deepseek-chat"

BASE_DIR = Path(__file__).parent.resolve()
PDF_DIR = BASE_DIR / "00_inbox_pdfs"
JSON_DIR = BASE_DIR / "01_extracted_json"
CSV_DIR = BASE_DIR / "02_summary_csv"
PROMPT_FILE = BASE_DIR / "prompt_paper_extraction.md"
THEME_FILE = BASE_DIR / "theme_buckets.md"
ERROR_LOG = BASE_DIR / "error_log.txt"

REQUEST_TIMEOUT = 180.0
REQUEST_INTERVAL = 5
MAX_PDF_CHARS = 30000

ALL_CSV_NAME = "_all_papers.csv"

# ============================================================
# CSVå­—æ®µé…ç½®ï¼ˆæŒ‰ç”¨æˆ·æœŸæœ›é¡ºåºæ’åˆ—ï¼‰
# ============================================================
CSV_FIELD_MAP = {
    "index": "ç¼–å·",
    "year": "å¹´ä»½",
    "venue": "æœŸåˆŠ",
    "authors": "ä½œè€…",
    "title": "æ ‡é¢˜",
    "paper_type": "è®ºæ–‡ç±»å‹",
    "domain_tags": "é¢†åŸŸæ ‡ç­¾",
    "keywords": "å…³é”®è¯",
    "research_object": "ç ”ç©¶å¯¹è±¡",
    "methodology": "ç ”ç©¶æ–¹æ³•",
    "problem": "ç ”ç©¶é—®é¢˜",
    "conclusion": "æ ¸å¿ƒç»“è®º",
    "implementation_path": "å…·ä½“å®ç°è·¯å¾„_ç®€æ˜",
    "contribution": "ä¸»è¦è´¡çŒ®",
    "score_rigor": "å­¦æœ¯ä¸¥è°¨åº¦",
    "score_innovation": "åˆ›æ–°ç¨‹åº¦",
    "score_practicality": "å®ç”¨ä»·å€¼",
    "score_impact": "å½±å“èŒƒå›´",
    "score_readability": "å¯è¯»æ€§",
    "overall_score": "ç»¼åˆè¯„åˆ†",
    "recommendation_level": "æ¨èç­‰çº§",
}

CSV_FIELDS = list(CSV_FIELD_MAP.keys())

# ============================================================
# æ•°æ®ç»“æ„
# ============================================================
@dataclass
class FolderStatus:
    """æ–‡ä»¶å¤¹çŠ¶æ€"""
    name: str
    path: Path
    total_pdfs: int = 0
    processed: int = 0
    pending: int = 0
    pdf_files: list = field(default_factory=list)

# ============================================================
# å·¥å…·å‡½æ•°
# ============================================================
client = None


def print_separator(char="=", length=70):
    print(char * length)


def print_header(text: str):
    print_separator()
    print(f"  {text}")
    print_separator()


def get_display_width(s: str) -> int:
    """è®¡ç®—å­—ç¬¦ä¸²çš„æ˜¾ç¤ºå®½åº¦ï¼ˆä¸­æ–‡/å…¨è§’=2ï¼Œå…¶ä»–=1ï¼‰"""
    import unicodedata
    width = 0
    for char in s:
        ea = unicodedata.east_asian_width(char)
        if ea in ('F', 'W'):  # Fullwidth, Wide
            width += 2
        else:
            width += 1
    return width


def pad_center(s: str, width: int) -> str:
    """å±…ä¸­å¯¹é½åˆ°æŒ‡å®šæ˜¾ç¤ºå®½åº¦"""
    current = get_display_width(s)
    if current >= width:
        return s
    total_pad = width - current
    left = total_pad // 2
    right = total_pad - left
    return ' ' * left + s + ' ' * right


def pad_left(s: str, width: int) -> str:
    """å·¦å¯¹é½åˆ°æŒ‡å®šæ˜¾ç¤ºå®½åº¦"""
    current = get_display_width(s)
    if current >= width:
        return s
    return s + ' ' * (width - current)


def init_client() -> bool:
    global client
    if not API_KEY:
        return False
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    return True


def log_error(filename: str, error: str):
    """è®°å½•é”™è¯¯åˆ°æ—¥å¿—æ–‡ä»¶"""
    with open(ERROR_LOG, 'a', encoding='utf-8') as f:
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        f.write(f"[{timestamp}] {filename}: {error}\n")


def extract_number_from_filename(filename: str) -> str:
    """ä»æ–‡ä»¶åæå–ç¼–å·å‰ç¼€ï¼ˆå¦‚ 01_xxx.pdf -> 01ï¼‰"""
    match = re.match(r'^(\d+)[_\-]', filename)
    return match.group(1) if match else ""


def format_list_as_numbered(val) -> str:
    """å°†æ•°ç»„è½¬ä¸ºç¼–å·æ–‡æœ¬ï¼Œå•å…ƒç´ ç›´æ¥è¿”å›"""
    if isinstance(val, list):
        if len(val) == 0:
            return ""
        if len(val) == 1:
            return str(val[0])
        return "\n".join(f"{i+1}. {item}" for i, item in enumerate(val))
    return str(val) if val is not None else ""


def extract_scores_from_json(json_obj: dict) -> dict:
    """
    ä»JSONä¸­æå–è¯„åˆ†ä¿¡æ¯

    Args:
        json_obj: LLMè¿”å›çš„å®Œæ•´JSONå¯¹è±¡

    Returns:
        dict: {score_rigor, score_innovation, score_practicality, score_impact, score_readability, overall_score, recommendation_level}
    """
    scores = json_obj.get("scores", {})
    recommendation = json_obj.get("recommendation", {})

    return {
        "score_rigor": scores.get("rigor", ""),
        "score_innovation": scores.get("innovation", ""),
        "score_practicality": scores.get("practicality", ""),
        "score_impact": scores.get("impact", ""),
        "score_readability": scores.get("readability", ""),
        "overall_score": scores.get("overall", ""),
        "recommendation_level": recommendation.get("level", ""),
    }


def format_implementation_path(impl_path_dict) -> str:
    """
    å°†implementation_pathå­—å…¸è½¬ä¸ºCSVç®€æ˜æ ¼å¼

    æ ¼å¼: ç»´åº¦ [å…³é”®è¯1 | å…³é”®è¯2] â†’ æè¿°

    Args:
        impl_path_dict: implementation_pathå­—æ®µçš„å€¼ï¼ˆå­—å…¸æˆ–å…¶ä»–æ ¼å¼ï¼‰

    Returns:
        str: æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²ï¼ˆå¤šè¡Œæ—¶ç”¨\nåˆ†éš”ï¼‰
    """
    if not impl_path_dict:
        return ""

    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ˆæ—§æ ¼å¼å…¼å®¹ï¼‰ï¼Œç›´æ¥è¿”å›
    if isinstance(impl_path_dict, str):
        return impl_path_dict

    # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œè½¬ä¸ºå­—ç¬¦ä¸²è¿”å›
    if not isinstance(impl_path_dict, dict):
        return str(impl_path_dict) if impl_path_dict else ""

    lines = []
    for idx, (key, value) in enumerate(impl_path_dict.items(), 1):
        if isinstance(value, dict):
            # æ–°ç»“æ„ï¼šåŒ…å«descriptionå’Œkeywords
            keywords = value.get("keywords", [])
            description = value.get("description", "").strip()

            # æ„å»ºå…³é”®è¯éƒ¨åˆ†
            if keywords:
                keywords_str = " | ".join(str(kw) for kw in keywords)
                lines.append(f"{idx}. {key} [{keywords_str}]")
            else:
                lines.append(f"{idx}. {key}")

            # æ·»åŠ æè¿°è¡Œ
            if description:
                lines.append(f"   â†’ {description}")
        else:
            # å…¼å®¹æ—§æ ¼å¼ï¼ˆçº¯å­—ç¬¦ä¸²ï¼‰
            lines.append(f"{idx}. {key}: {value}")

    return "\n".join(lines)


# ============================================================
# æ­¥éª¤1: æ£€æŸ¥é…ç½®æ–‡ä»¶
# ============================================================
def check_required_files() -> bool:
    """æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    print("\nğŸ“ æ£€æŸ¥é…ç½®æ–‡ä»¶...")
    all_ok = True
    
    checks = [
        (PROMPT_FILE, "Promptæ¨¡æ¿"),
        (THEME_FILE, "ä¸»é¢˜æ¡¶é…ç½®"),
    ]
    
    for path, name in checks:
        if path.exists():
            print(f"   âœ… {name}: {path.name}")
        else:
            print(f"   âŒ {name}ä¸å­˜åœ¨: {path}")
            all_ok = False
    
    # PDFç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»º
    if not PDF_DIR.exists():
        PDF_DIR.mkdir(parents=True)
        print(f"   âœ… PDFç›®å½•: {PDF_DIR.name} (å·²åˆ›å»º)")
    else:
        print(f"   âœ… PDFç›®å½•: {PDF_DIR.name}")
    
    return all_ok


# ============================================================
# æ­¥éª¤2: åŒæ­¥æ–‡ä»¶å¤¹ç»“æ„
# ============================================================
def parse_theme_buckets() -> list[str]:
    """ä»ä¸»é¢˜æ¡¶é…ç½®æ–‡ä»¶è§£æä¸€çº§ä¸»é¢˜åç§°"""
    content = THEME_FILE.read_text(encoding='utf-8')
    themes = []
    for line in content.split('\n'):
        line = line.strip()
        if line.startswith('## ') and not line.startswith('## '):
            theme_name = line[3:].strip()
            if theme_name:
                themes.append(theme_name)
        elif line.startswith('##'):
            theme_name = line[2:].strip()
            if theme_name:
                themes.append(theme_name)
    return themes


def sync_folder_structure() -> None:
    """æ ¹æ®ä¸»é¢˜æ¡¶é…ç½®åŒæ­¥æ–‡ä»¶å¤¹ç»“æ„"""
    print("\nğŸ“‚ åŒæ­¥æ–‡ä»¶å¤¹ç»“æ„...")
    
    themes = parse_theme_buckets()
    print(f"   ä»ä¸»é¢˜æ¡¶é…ç½®ä¸­è§£æåˆ° {len(themes)} ä¸ªä¸»é¢˜")
    
    if not themes:
        print("   âš ï¸ æœªè§£æåˆ°ä»»ä½•ä¸»é¢˜ï¼Œè¯·æ£€æŸ¥theme_buckets.mdæ ¼å¼")
        return
    
    # è·å–å·²å­˜åœ¨çš„æ–‡ä»¶å¤¹
    existing_folders = set()
    if PDF_DIR.exists():
        for item in PDF_DIR.iterdir():
            if item.is_dir():
                existing_folders.add(item.name)
    
    # åˆ›å»ºç¼ºå¤±çš„æ–‡ä»¶å¤¹
    created_count = 0
    for theme in themes:
        folder_path = PDF_DIR / theme
        if theme not in existing_folders:
            folder_path.mkdir(parents=True, exist_ok=True)
            print(f"   âœ… æ–°å»º: {theme}")
            created_count += 1
    
    skipped_count = len(themes) - created_count
    if skipped_count > 0:
        print(f"   â© å·²å­˜åœ¨: {skipped_count} ä¸ªæ–‡ä»¶å¤¹ï¼ˆè·³è¿‡ï¼‰")
    
    print("   åŒæ­¥å®Œæˆ")


# ============================================================
# æ­¥éª¤3: æµ‹è¯•APIè¿æ¥
# ============================================================
def test_api_connection() -> bool:
    """æµ‹è¯•APIè¿æ¥"""
    print("\nğŸ”‘ æµ‹è¯•APIè¿æ¥...")
    print(f"   ç«¯ç‚¹: {BASE_URL}")
    print(f"   æ¨¡å‹: {MODEL_NAME}")
    
    if not API_KEY:
        print("   âŒ API Keyä¸ºç©ºï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY")
        return False
    
    if not init_client():
        print("   âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥")
        return False
    
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": "æµ‹è¯•"}],
            max_tokens=10,
            timeout=30.0
        )
        if response and response.choices[0].message.content:
            print("   âœ… APIè¿æ¥æˆåŠŸ")
            return True
    except Exception as e:
        print(f"   âŒ è¿æ¥å¤±è´¥: {e}")
    
    return False


# ============================================================
# æ­¥éª¤4: æ‰«æPDFæ–‡ä»¶
# ============================================================
def get_json_path_for_pdf(pdf_path: Path, folder_name: str) -> Path:
    """æ ¹æ®PDFè·¯å¾„ç”Ÿæˆå¯¹åº”çš„JSONè·¯å¾„"""
    return JSON_DIR / folder_name / (pdf_path.stem + ".json")


def scan_folders() -> tuple[list[FolderStatus], list[Path]]:
    """
    æ‰«æPDFç›®å½•
    è¿”å›: (æœ‰PDFçš„æ–‡ä»¶å¤¹åˆ—è¡¨, æ ¹ç›®å½•æ•£è½çš„PDFåˆ—è¡¨)
    """
    folders = {}
    root_pdfs = []
    
    # æ‰«ææ‰€æœ‰PDF
    for item in PDF_DIR.iterdir():
        if item.is_file() and item.suffix.lower() == '.pdf':
            # æ ¹ç›®å½•çš„PDF
            root_pdfs.append(item)
        elif item.is_dir():
            # å­æ–‡ä»¶å¤¹
            folder_name = item.name
            pdf_files = sorted(
                [f for f in item.iterdir() if f.is_file() and f.suffix.lower() == '.pdf'],
                key=lambda x: x.name
            )
            
            if pdf_files:  # åªè®°å½•æœ‰PDFçš„æ–‡ä»¶å¤¹
                folder = FolderStatus(
                    name=folder_name,
                    path=item,
                    total_pdfs=len(pdf_files),
                    pdf_files=pdf_files
                )
                
                # ç»Ÿè®¡å·²å¤„ç†æ•°é‡
                for pdf_path in pdf_files:
                    json_path = get_json_path_for_pdf(pdf_path, folder_name)
                    if json_path.exists():
                        folder.processed += 1
                    else:
                        folder.pending += 1
                
                folders[folder_name] = folder
    
    # æŒ‰åç§°æ’åº
    result = list(folders.values())
    result.sort(key=lambda x: x.name)
    
    return result, root_pdfs


def display_folder_status(folders: list[FolderStatus], root_pdfs: list[Path], empty_folder_count: int):
    """æ˜¾ç¤ºæ–‡ä»¶å¤¹çŠ¶æ€è¡¨"""
    print("\nğŸ“Š æ‰«æPDFæ–‡ä»¶...")
    
    # è­¦å‘Šæ ¹ç›®å½•PDF
    if root_pdfs:
        print(f"\n   âš ï¸ è­¦å‘Š: å‘ç° {len(root_pdfs)} ä¸ªPDFåœ¨æ ¹ç›®å½•ï¼Œè¯·ç§»åˆ°å­æ–‡ä»¶å¤¹")
        for pdf in root_pdfs[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
            print(f"      - {pdf.name}")
        if len(root_pdfs) > 5:
            print(f"      ... ç­‰å…± {len(root_pdfs)} ä¸ªæ–‡ä»¶")
        print("   è¿™äº›æ–‡ä»¶å°†è¢«è·³è¿‡")
    
    if not folders:
        print("\n   âš ï¸ æœªæ‰¾åˆ°ä»»ä½•PDFæ–‡ä»¶ï¼ˆè¯·å°†PDFæ”¾å…¥å­æ–‡ä»¶å¤¹ä¸­ï¼‰")
        return
    
    # è¡¨æ ¼åˆ—å®½å®šä¹‰ï¼ˆæ˜¾ç¤ºå®½åº¦ï¼‰
    COL_NO = 6       # åºå·åˆ—
    COL_NAME = 32    # æ–‡ä»¶å¤¹åç§°åˆ—
    COL_NUM = 8      # æ•°å­—åˆ—

    # è¡¨æ ¼
    print()
    print(f"â”Œ{'â”€'*COL_NO}â”¬{'â”€'*COL_NAME}â”¬{'â”€'*COL_NUM}â”¬{'â”€'*COL_NUM}â”¬{'â”€'*COL_NUM}â”")
    print(f"â”‚{pad_center('åºå·', COL_NO)}â”‚{pad_center('æ–‡ä»¶å¤¹åç§°', COL_NAME)}â”‚{pad_center('PDFæ€»æ•°', COL_NUM)}â”‚{pad_center('å·²å¤„ç†', COL_NUM)}â”‚{pad_center('å¾…å¤„ç†', COL_NUM)}â”‚")
    print(f"â”œ{'â”€'*COL_NO}â”¼{'â”€'*COL_NAME}â”¼{'â”€'*COL_NUM}â”¼{'â”€'*COL_NUM}â”¼{'â”€'*COL_NUM}â”¤")

    for i, folder in enumerate(folders, 1):
        name_display = folder.name
        # æˆªæ–­è¿‡é•¿çš„åç§°ï¼ˆæŒ‰æ˜¾ç¤ºå®½åº¦è®¡ç®—ï¼‰
        if get_display_width(name_display) > COL_NAME - 2:
            while get_display_width(name_display + "...") > COL_NAME - 2:
                name_display = name_display[:-1]
            name_display = name_display + "..."

        no_str = f"[{i}]"
        print(f"â”‚{pad_center(no_str, COL_NO)}â”‚ {pad_left(name_display, COL_NAME - 1)}â”‚{pad_center(str(folder.total_pdfs), COL_NUM)}â”‚{pad_center(str(folder.processed), COL_NUM)}â”‚{pad_center(str(folder.pending), COL_NUM)}â”‚")

    # æ±‡æ€»è¡Œ
    total_pdfs = sum(f.total_pdfs for f in folders)
    total_processed = sum(f.processed for f in folders)
    total_pending = sum(f.pending for f in folders)

    print(f"â”œ{'â”€'*COL_NO}â”¼{'â”€'*COL_NAME}â”¼{'â”€'*COL_NUM}â”¼{'â”€'*COL_NUM}â”¼{'â”€'*COL_NUM}â”¤")
    print(f"â”‚{pad_center('åˆè®¡', COL_NO)}â”‚{' '*COL_NAME}â”‚{pad_center(str(total_pdfs), COL_NUM)}â”‚{pad_center(str(total_processed), COL_NUM)}â”‚{pad_center(str(total_pending), COL_NUM)}â”‚")
    print(f"â””{'â”€'*COL_NO}â”´{'â”€'*COL_NAME}â”´{'â”€'*COL_NUM}â”´{'â”€'*COL_NUM}â”´{'â”€'*COL_NUM}â”˜")
    
    # ç©ºæ–‡ä»¶å¤¹æç¤º
    if empty_folder_count > 0:
        print(f"\n   ğŸ’¡ æç¤º: æœ‰ {empty_folder_count} ä¸ªç©ºæ–‡ä»¶å¤¹æœªæ˜¾ç¤ºï¼ˆæ— PDFï¼‰")


# ============================================================
# æ­¥éª¤5: ç”¨æˆ·äº¤äº’
# ============================================================
def get_user_choice(folders: list[FolderStatus]) -> tuple[str, list[int], bool]:
    """
    è·å–ç”¨æˆ·é€‰æ‹©
    è¿”å›: (æ“ä½œæ¨¡å¼, é€‰ä¸­çš„æ–‡ä»¶å¤¹ç´¢å¼•åˆ—è¡¨, æ˜¯å¦è¦†ç›–)
    """
    print("\nè¯·é€‰æ‹©æ“ä½œæ¨¡å¼:")
    print("  [A] å…¨éƒ¨æ‰§è¡Œ - å¤„ç†æ‰€æœ‰å¾…å¤„ç†çš„PDFï¼ˆè·³è¿‡å·²å¤„ç†ï¼‰")
    print("  [R] å…¨éƒ¨é‡è·‘ - é‡æ–°å¤„ç†æ‰€æœ‰PDFï¼ˆè¦†ç›–å·²æœ‰ç»“æœï¼‰")
    print("  [S] é€‰æ‹©æ‰§è¡Œ - é€‰æ‹©ç‰¹å®šæ–‡ä»¶å¤¹å¤„ç†")
    print("  [Q] é€€å‡º")
    print()
    
    while True:
        choice = input("è¯·è¾“å…¥é€‰é¡¹ [A/R/S/Q]: ").strip().upper()
        
        if choice == 'Q':
            return ('quit', [], False)
        
        elif choice == 'A':
            indices = [i for i, f in enumerate(folders) if f.pending > 0]
            if not indices:
                print("   âš ï¸ æ²¡æœ‰å¾…å¤„ç†çš„æ–‡ä»¶")
                return ('quit', [], False)
            return ('all', indices, False)
        
        elif choice == 'R':
            confirm = input("   âš ï¸ ç¡®è®¤è¦†ç›–æ‰€æœ‰å·²å¤„ç†çš„ç»“æœ? [y/N]: ").strip().lower()
            if confirm == 'y':
                indices = [i for i, f in enumerate(folders) if f.total_pdfs > 0]
                return ('all', indices, True)
            else:
                print("   å·²å–æ¶ˆ")
                continue
        
        elif choice == 'S':
            return get_folder_selection(folders)
        
        else:
            print("   âŒ æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°è¾“å…¥")


def get_folder_selection(folders: list[FolderStatus]) -> tuple[str, list[int], bool]:
    """è·å–ç”¨æˆ·é€‰æ‹©çš„æ–‡ä»¶å¤¹"""
    print()
    print("è¯·è¾“å…¥è¦å¤„ç†çš„æ–‡ä»¶å¤¹åºå·:")
    print("  - å•ä¸ª: 1")
    print("  - å¤šä¸ª: 1,3,5")
    print("  - èŒƒå›´: 1-5")
    print("  - æ··åˆ: 1,3-5,7")
    print("  - è¿”å›: B")
    print()
    
    while True:
        selection = input("è¯·è¾“å…¥åºå·: ").strip()
        
        if selection.upper() == 'B':
            return get_user_choice(folders)
        
        try:
            indices = parse_selection(selection, len(folders))
            if not indices:
                print("   âŒ æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶å¤¹")
                continue
            
            # æ˜¾ç¤ºé€‰ä¸­çš„æ–‡ä»¶å¤¹
            print(f"\n   å·²é€‰æ‹© {len(indices)} ä¸ªæ–‡ä»¶å¤¹:")
            for i in indices:
                f = folders[i]
                print(f"     - {f.name} (å¾…å¤„ç†: {f.pending})")
            
            # è¯¢é—®æ˜¯å¦è¦†ç›–
            has_processed = any(folders[i].processed > 0 for i in indices)
            overwrite = False
            if has_processed:
                print()
                print("   æ£€æµ‹åˆ°å·²æœ‰å¤„ç†ç»“æœï¼Œè¯·é€‰æ‹©:")
                print("   [N] è·³è¿‡å·²å¤„ç†ï¼ˆé»˜è®¤ï¼‰")
                print("   [O] è¦†ç›–å·²å¤„ç†")
                ow_choice = input("   è¯·é€‰æ‹© [N/O]: ").strip().upper()
                overwrite = (ow_choice == 'O')
            
            confirm = input("\n   ç¡®è®¤å¼€å§‹å¤„ç†? [Y/n]: ").strip().lower()
            if confirm in ('', 'y', 'yes'):
                return ('select', indices, overwrite)
            else:
                print("   å·²å–æ¶ˆ")
                continue
                
        except ValueError as e:
            print(f"   âŒ {e}")
            continue


def parse_selection(selection: str, max_num: int) -> list[int]:
    """è§£æç”¨æˆ·è¾“å…¥çš„åºå·"""
    indices = set()
    parts = selection.replace(' ', '').split(',')
    
    for part in parts:
        if not part:
            continue
        if '-' in part:
            try:
                start, end = part.split('-')
                start, end = int(start), int(end)
                if start < 1 or end > max_num or start > end:
                    raise ValueError(f"èŒƒå›´ {part} æ— æ•ˆ")
                indices.update(range(start - 1, end))
            except:
                raise ValueError(f"æ— æ³•è§£æèŒƒå›´: {part}")
        else:
            try:
                num = int(part)
                if num < 1 or num > max_num:
                    raise ValueError(f"åºå· {num} è¶…å‡ºèŒƒå›´ (1-{max_num})")
                indices.add(num - 1)
            except ValueError:
                raise ValueError(f"æ— æ³•è§£æåºå·: {part}")
    
    return sorted(list(indices))


# ============================================================
# æ­¥éª¤6: æ ¸å¿ƒå¤„ç†é€»è¾‘
# ============================================================
def load_theme_buckets() -> str:
    """è¯»å–ä¸»é¢˜æ¡¶é…ç½®æ–‡ä»¶å†…å®¹"""
    return THEME_FILE.read_text(encoding='utf-8')


def load_scoring_config(domain_tag: str) -> dict:
    """
    åŠ¨æ€åŠ è½½è®ºæ–‡é¢†åŸŸå¯¹åº”çš„è¯„åˆ†é…ç½®

    å½“å‰ç‰ˆæœ¬ï¼ˆP0ï¼‰ï¼šå§‹ç»ˆè¿”å›æ ‡å‡†æƒé‡
    åæœŸç‰ˆæœ¬ï¼ˆP1+ï¼‰ï¼šæ ¹æ®domain_tagåŠ è½½å¯¹åº”é¢†åŸŸçš„scoring_*.mdæ–‡ä»¶

    Args:
        domain_tag: è®ºæ–‡çš„ä¸»é¢˜æ¡¶åç§°ï¼ˆå¦‚ "äººå·¥æ™ºèƒ½æ•™è‚²åº”ç”¨"ï¼‰

    Returns:
        dict: æƒé‡é…ç½® {rigor, innovation, practicality, impact, readability}
    """
    # TODO: P1 å®ç°åŠ¨æ€åŠ è½½
    # domain_mapping = {
    #     "äººå·¥æ™ºèƒ½æ•™è‚²åº”ç”¨": "education",
    #     "æ•™è‚²ç†è®ºç ”ç©¶": "education",
    #     "å·¥ç¨‹åº”ç”¨": "engineering",
    #     ...
    # }
    # domain = domain_mapping.get(domain_tag, "framework")
    # scoring_file = BASE_DIR / "scoring" / f"scoring_{domain}.md"
    # if scoring_file.exists():
    #     return parse_scoring_config_from_markdown(scoring_file)

    # å½“å‰é˜¶æ®µï¼šç›´æ¥è¿”å›P0é»˜è®¤æƒé‡
    return {
        "rigor": 0.30,
        "innovation": 0.25,
        "practicality": 0.25,
        "impact": 0.15,
        "readability": 0.05
    }


def load_prompt_template() -> str:
    """è¯»å–Promptæ¨¡æ¿"""
    return PROMPT_FILE.read_text(encoding='utf-8')


def build_full_prompt(prompt_template: str, theme_content: str, pdf_text: str) -> str:
    """æ„å»ºå®Œæ•´çš„Prompt"""
    prompt_with_theme = prompt_template.replace("{THEME_BUCKETS}", theme_content)
    return f"""{prompt_with_theme}

---

ä»¥ä¸‹æ˜¯è®ºæ–‡çš„å…¨æ–‡å†…å®¹ï¼Œè¯·æŒ‰ç…§ä¸Šè¿°è¦æ±‚è¿›è¡Œä¿¡æ¯æå–ï¼š

{pdf_text}
"""


def extract_pdf_text(pdf_path: Path) -> str:
    """æå–PDFæ–‡æœ¬å†…å®¹"""
    text_parts = []
    doc = fitz.open(str(pdf_path))
    for page_num, page in enumerate(doc, 1):
        text = page.get_text("text")
        if text.strip():
            text_parts.append(f"--- ç¬¬ {page_num} é¡µ ---\n{text}")
    doc.close()
    
    full_text = "\n\n".join(text_parts)
    if len(full_text) > MAX_PDF_CHARS:
        full_text = full_text[:MAX_PDF_CHARS] + "\n\n[æ³¨: æ–‡æœ¬å·²æˆªæ–­]"
    
    return full_text


def clean_json_response(text: str) -> str:
    """æ¸…æ´—æ¨¡å‹è¿”å›çš„JSON"""
    text = text.strip()
    if text.startswith("```json"):
        text = text[7:]
    elif text.startswith("```"):
        text = text[3:]
    if text.endswith("```"):
        text = text[:-3]
    return text.strip()


def call_llm(full_prompt: str) -> str:
    """è°ƒç”¨LLM API"""
    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†æåŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·æä¾›çš„JSON Schemaæ ¼å¼è¾“å‡ºç»“æœï¼Œåªè¾“å‡ºJSONï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜ã€‚"
            },
            {
                "role": "user",
                "content": full_prompt
            }
        ],
        temperature=0.1,
        max_tokens=4096,
        timeout=REQUEST_TIMEOUT
    )
    return response.choices[0].message.content


def init_csv(csv_path: Path):
    """åˆå§‹åŒ–CSVæ–‡ä»¶"""
    csv_path.parent.mkdir(parents=True, exist_ok=True)
    if not csv_path.exists():
        with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            headers = [CSV_FIELD_MAP[k] for k in CSV_FIELDS]
            writer.writerow(headers)


def append_to_csv(csv_path: Path, data: dict, index_value: str = ""):
    """
    è¿½åŠ æ•°æ®åˆ°CSV

    Args:
        csv_path: CSVæ–‡ä»¶è·¯å¾„
        data: è®ºæ–‡æ•°æ®å­—å…¸
        index_value: ç¼–å·å€¼ï¼ˆåˆ†ä¸»é¢˜è¡¨ç”¨æ–‡ä»¶åç¼–å·ï¼Œæ€»è¡¨ç”¨å…¨å±€ç¼–å·ï¼‰
    """
    # å…ˆæå–è¯„åˆ†ä¿¡æ¯ï¼ˆå¦‚æœJSONä¸­åŒ…å«scoreså­—æ®µï¼‰
    scores_data = extract_scores_from_json(data)

    row = []
    for key in CSV_FIELDS:
        if key == "index":
            # ç¼–å·å­—æ®µä½¿ç”¨ä¼ å…¥çš„index_value
            row.append(index_value)
        elif key in ("problem", "conclusion"):
            # ç ”ç©¶é—®é¢˜å’Œç»“è®ºä½¿ç”¨ç¼–å·åˆ—è¡¨æ ¼å¼
            val = data.get(key, "")
            row.append(format_list_as_numbered(val))
        elif key == "implementation_path":
            # å®ç°è·¯å¾„ä½¿ç”¨æ ¼å¼åŒ–å‡½æ•°
            val = data.get(key, "")
            row.append(format_implementation_path(val))
        elif key in ("keywords", "domain_tags"):
            # å…³é”®è¯å’Œé¢†åŸŸæ ‡ç­¾ä½¿ç”¨é€—å·åˆ†éš”
            val = data.get(key, [])
            if isinstance(val, list):
                row.append(", ".join(str(v) for v in val))
            else:
                row.append(str(val) if val else "")
        elif key in ("score_rigor", "score_innovation", "score_practicality", "score_impact", "score_readability", "overall_score", "recommendation_level"):
            # è¯„åˆ†å­—æ®µä»scores_dataä¸­å–
            val = scores_data.get(key, "")
            row.append(str(val) if val else "")
        else:
            val = data.get(key, "")
            if val is None:
                val = ""
            row.append(str(val))

    with open(csv_path, 'a', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow(row)


def process_folder(
    folder: FolderStatus,
    prompt_template: str,
    theme_content: str,
    overwrite: bool = False,
    global_index_start: int = 1
) -> tuple[dict, int]:
    """
    å¤„ç†å•ä¸ªæ–‡ä»¶å¤¹

    Args:
        folder: æ–‡ä»¶å¤¹çŠ¶æ€
        prompt_template: Promptæ¨¡æ¿
        theme_content: ä¸»é¢˜æ¡¶å†…å®¹
        overwrite: æ˜¯å¦è¦†ç›–å·²æœ‰ç»“æœ
        global_index_start: å…¨å±€ç¼–å·èµ·å§‹å€¼

    Returns:
        (ç»Ÿè®¡å­—å…¸, ä¸‹ä¸€ä¸ªå…¨å±€ç¼–å·)
    """
    stats = {"success": 0, "skip": 0, "fail": 0}
    global_index = global_index_start
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    json_folder = JSON_DIR / folder.name
    json_folder.mkdir(parents=True, exist_ok=True)
    
    csv_path = CSV_DIR / f"{folder.name}.csv"
    all_csv_path = CSV_DIR / ALL_CSV_NAME
    
    # è¦†ç›–æ¨¡å¼ä¸‹åˆ é™¤å·²æœ‰CSV
    if overwrite and csv_path.exists():
        csv_path.unlink()
    
    init_csv(csv_path)
    init_csv(all_csv_path)
    
    # è®¡ç®—å¾…å¤„ç†æ•°é‡
    to_process = []
    for pdf_path in folder.pdf_files:
        json_path = json_folder / (pdf_path.stem + ".json")
        if overwrite or not json_path.exists():
            to_process.append(pdf_path)
        else:
            stats["skip"] += 1
    
    if not to_process:
        return stats, global_index
    
    # å¤„ç†æ¯ä¸ªPDF
    for i, pdf_path in enumerate(to_process, 1):
        json_path = json_folder / (pdf_path.stem + ".json")
        
        print(f"\n   [{i}/{len(to_process)}] {pdf_path.name}")
        
        try:
            # æå–PDFæ–‡æœ¬
            print(f"      ğŸ“„ æå–æ–‡æœ¬...", end=" ")
            pdf_text = extract_pdf_text(pdf_path)
            print(f"{len(pdf_text)}å­—ç¬¦")
            
            # è°ƒç”¨LLM
            print(f"      ğŸ¤– è°ƒç”¨LLM...")
            start_time = time.time()
            response_text = call_llm(
                build_full_prompt(prompt_template, theme_content, pdf_text)
            )
            elapsed = time.time() - start_time
            print(f"      âœ… å“åº”å®Œæˆ ({elapsed:.1f}ç§’)")
            
            # è§£æJSON
            clean_text = clean_json_response(response_text)
            data = json.loads(clean_text)
            
            # æ·»åŠ æ¥æºæ–‡ä»¶å¤¹
            data["source_folder"] = folder.name
            
            # ä¿å­˜JSON
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"      ğŸ’¾ JSON ä¿å­˜æˆåŠŸ")
            
            # æå–æœ¬åœ°ç¼–å·ï¼ˆä»æ–‡ä»¶åï¼‰
            local_index = extract_number_from_filename(pdf_path.name)

            # è¿½åŠ CSVï¼ˆåˆ†ä¸»é¢˜è¡¨ç”¨æœ¬åœ°ç¼–å·ï¼Œæ€»è¡¨ç”¨å…¨å±€ç¼–å·ï¼‰
            append_to_csv(csv_path, data, index_value=local_index)
            append_to_csv(all_csv_path, data, index_value=str(global_index))
            print(f"      ğŸ“ CSV æ›´æ–°æˆåŠŸ (æœ¬åœ°ç¼–å·: {local_index}, å…¨å±€ç¼–å·: {global_index})")

            stats["success"] += 1
            global_index += 1
            
        except json.JSONDecodeError as e:
            print(f"      âŒ JSONè§£æå¤±è´¥: {e}")
            stats["fail"] += 1
            log_error(pdf_path.name, f"JSONè§£æå¤±è´¥: {e}")
            
        except Exception as e:
            print(f"      âŒ å¤„ç†å¤±è´¥: {e}")
            stats["fail"] += 1
            log_error(pdf_path.name, str(e))
        
        # è¯·æ±‚é—´éš”
        if i < len(to_process):
            print(f"      â³ ç­‰å¾…{REQUEST_INTERVAL}ç§’...")
            time.sleep(REQUEST_INTERVAL)

    return stats, global_index


# ============================================================
# ä¸»å‡½æ•°
# ============================================================
def main():
    print_header("ğŸ“š è®ºæ–‡èº«ä»½å¡è‡ªåŠ¨æå–å·¥å…· v2.0")
    
    # æ­¥éª¤1: æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not check_required_files():
        print("\nâš ï¸ è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶åé‡è¯•")
        return
    
    # æ­¥éª¤2: åŒæ­¥æ–‡ä»¶å¤¹ç»“æ„
    sync_folder_structure()
    
    # æ­¥éª¤3: æµ‹è¯•APIè¿æ¥
    if not test_api_connection():
        print("\nâš ï¸ APIè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return
    
    # æ­¥éª¤4: æ‰«æPDFæ–‡ä»¶
    folders, root_pdfs = scan_folders()
    
    # è®¡ç®—ç©ºæ–‡ä»¶å¤¹æ•°é‡
    themes = parse_theme_buckets()
    existing_folder_names = {f.name for f in folders}
    empty_folder_count = len([t for t in themes if t not in existing_folder_names])
    
    # æ˜¾ç¤ºçŠ¶æ€
    display_folder_status(folders, root_pdfs, empty_folder_count)
    
    if not folders:
        return
    
    # æ­¥éª¤5: ç”¨æˆ·é€‰æ‹©
    mode, selected_indices, overwrite = get_user_choice(folders)
    
    if mode == 'quit':
        print("\nğŸ‘‹ å·²é€€å‡º")
        return
    
    # æ­¥éª¤6: åŠ è½½é…ç½®å¹¶å¤„ç†
    print("\nğŸ“‚ åŠ è½½é…ç½®æ–‡ä»¶...")
    prompt_template = load_prompt_template()
    theme_content = load_theme_buckets()
    print("   âœ… é…ç½®å·²åŠ è½½")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    JSON_DIR.mkdir(parents=True, exist_ok=True)
    CSV_DIR.mkdir(parents=True, exist_ok=True)
    
    # å¤„ç†é€‰ä¸­çš„æ–‡ä»¶å¤¹
    total_stats = {"success": 0, "skip": 0, "fail": 0}
    global_index = 1  # å…¨å±€ç¼–å·ä»1å¼€å§‹

    for idx in selected_indices:
        folder = folders[idx]

        # æ— å¾…å¤„ç†ä¸”éè¦†ç›–æ¨¡å¼åˆ™è·³è¿‡
        if not overwrite and folder.pending == 0:
            continue

        print_separator("-")
        print("ğŸš€ å¼€å§‹ä»»åŠ¡")
        print_separator("-")
        print(f"ğŸ“ æ­£åœ¨å¤„ç†: {folder.name}")
        print(f"   PDFæ•°é‡: {folder.total_pdfs} | å·²å¤„ç†: {folder.processed} | å¾…å¤„ç†: {folder.pending}")
        print_separator("-")

        stats, global_index = process_folder(
            folder, prompt_template, theme_content, overwrite, global_index
        )

        for key in total_stats:
            total_stats[key] += stats[key]

        print(f"\n   ğŸ“Š æœ¬æ–‡ä»¶å¤¹å®Œæˆ: æˆåŠŸ {stats['success']} | è·³è¿‡ {stats['skip']} | å¤±è´¥ {stats['fail']}")
    
    # æœ€ç»ˆæ±‡æ€»
    print_separator()
    print("ğŸ“Š å…¨éƒ¨å¤„ç†å®Œæˆ")
    print_separator()
    print(f"   âœ… æˆåŠŸ: {total_stats['success']}")
    print(f"   â© è·³è¿‡: {total_stats['skip']}")
    print(f"   âŒ å¤±è´¥: {total_stats['fail']}")
    print()
    print(f"   ğŸ“‚ è¾“å‡ºä½ç½®:")
    print(f"      JSON: {JSON_DIR}/")
    print(f"      CSV:  {CSV_DIR}/")
    print(f"      æ±‡æ€»: {CSV_DIR / ALL_CSV_NAME}")
    
    if total_stats["fail"] > 0:
        print(f"      é”™è¯¯æ—¥å¿—: {ERROR_LOG}")
    
    print_separator()


if __name__ == "__main__":
    main()
